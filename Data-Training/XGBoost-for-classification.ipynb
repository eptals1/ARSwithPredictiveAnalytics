{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRE-PROCESSING STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from resume: Accounting Profesional.pdf\n",
      "Extracting text from resume: Call Center Agent.pdf\n",
      "Extracting text from resume: Computer-Engineer.pdf\n",
      "Extracting text from resume: Cybersecurity.pdf\n",
      "Extracting text from resume: Data-Encoder.pdf\n",
      "Extracting text from resume: Data-Scientist.pdf\n",
      "Extracting text from resume: Freelance.pdf\n",
      "Extracting text from resume: Graphic Artist.pdf\n",
      "Extracting text from resume: Instructor.pdf\n",
      "Extracting text from resume: IT-student.pdf\n",
      "Extracting text from resume: Profile (0).pdf\n",
      "Extracting text from resume: Profile (1).pdf\n",
      "Extracting text from resume: Profile (10).pdf\n",
      "Extracting text from resume: Profile (100).pdf\n",
      "Extracting text from resume: Profile (101).pdf\n",
      "Extracting text from resume: profile (102).pdf\n",
      "Extracting text from resume: Profile (103).pdf\n",
      "Extracting text from resume: Profile (104).pdf\n",
      "Extracting text from resume: Profile (105).pdf\n",
      "Extracting text from resume: Profile (106).pdf\n",
      "Extracting text from resume: Profile (107).pdf\n",
      "Extracting text from resume: Profile (108).pdf\n",
      "Extracting text from resume: Profile (109).pdf\n",
      "Extracting text from resume: Profile (11).pdf\n",
      "Extracting text from resume: Profile (110).pdf\n",
      "Extracting text from resume: Profile (111).pdf\n",
      "Extracting text from resume: Profile (112).pdf\n",
      "Extracting text from resume: Profile (12).pdf\n",
      "Extracting text from resume: Profile (13).pdf\n",
      "Extracting text from resume: Profile (14).pdf\n",
      "Extracting text from resume: Profile (15).pdf\n",
      "Extracting text from resume: Profile (16).pdf\n",
      "Extracting text from resume: Profile (17).pdf\n",
      "Extracting text from resume: Profile (18).pdf\n",
      "Extracting text from resume: Profile (19).pdf\n",
      "Extracting text from resume: Profile (2).pdf\n",
      "Extracting text from resume: Profile (20).pdf\n",
      "Extracting text from resume: Profile (21).pdf\n",
      "Extracting text from resume: Profile (22).pdf\n",
      "Extracting text from resume: Profile (23).pdf\n",
      "Extracting text from resume: Profile (24).pdf\n",
      "Extracting text from resume: Profile (25).pdf\n",
      "Extracting text from resume: Profile (26).pdf\n",
      "Extracting text from resume: Profile (27).pdf\n",
      "Extracting text from resume: Profile (28).pdf\n",
      "Extracting text from resume: Profile (29).pdf\n",
      "Extracting text from resume: Profile (3).pdf\n",
      "Extracting text from resume: Profile (30).pdf\n",
      "Extracting text from resume: Profile (31).pdf\n",
      "Extracting text from resume: Profile (32).pdf\n",
      "Extracting text from resume: Profile (33).pdf\n",
      "Extracting text from resume: Profile (34).pdf\n",
      "Extracting text from resume: Profile (35).pdf\n",
      "Extracting text from resume: Profile (36).pdf\n",
      "Extracting text from resume: Profile (37).pdf\n",
      "Extracting text from resume: Profile (38).pdf\n",
      "Extracting text from resume: Profile (39).pdf\n",
      "Extracting text from resume: Profile (4).pdf\n",
      "Extracting text from resume: Profile (40).pdf\n",
      "Extracting text from resume: Profile (41).pdf\n",
      "Extracting text from resume: Profile (42).pdf\n",
      "Extracting text from resume: Profile (43).pdf\n",
      "Extracting text from resume: Profile (44).pdf\n",
      "Extracting text from resume: Profile (45).pdf\n",
      "Extracting text from resume: Profile (46).pdf\n",
      "Extracting text from resume: Profile (47).pdf\n",
      "Extracting text from resume: Profile (48).pdf\n",
      "Extracting text from resume: Profile (49).pdf\n",
      "Extracting text from resume: Profile (5).pdf\n",
      "Extracting text from resume: Profile (50).pdf\n",
      "Extracting text from resume: Profile (51).pdf\n",
      "Extracting text from resume: Profile (52).pdf\n",
      "Extracting text from resume: Profile (53).pdf\n",
      "Extracting text from resume: Profile (54).pdf\n",
      "Extracting text from resume: Profile (55).pdf\n",
      "Extracting text from resume: Profile (56).pdf\n",
      "Extracting text from resume: Profile (57).pdf\n",
      "Extracting text from resume: Profile (58).pdf\n",
      "Extracting text from resume: Profile (59).pdf\n",
      "Extracting text from resume: Profile (6).pdf\n",
      "Extracting text from resume: Profile (60).pdf\n",
      "Extracting text from resume: Profile (61).pdf\n",
      "Extracting text from resume: Profile (62).pdf\n",
      "Extracting text from resume: Profile (63).pdf\n",
      "Extracting text from resume: Profile (64).pdf\n",
      "Extracting text from resume: Profile (65).pdf\n",
      "Extracting text from resume: Profile (66).pdf\n",
      "Extracting text from resume: Profile (67).pdf\n",
      "Extracting text from resume: Profile (68).pdf\n",
      "Extracting text from resume: Profile (69).pdf\n",
      "Extracting text from resume: Profile (7).pdf\n",
      "Extracting text from resume: Profile (70).pdf\n",
      "Extracting text from resume: Profile (71).pdf\n",
      "Extracting text from resume: Profile (72).pdf\n",
      "Extracting text from resume: Profile (73).pdf\n",
      "Extracting text from resume: Profile (74).pdf\n",
      "Extracting text from resume: Profile (75).pdf\n",
      "Extracting text from resume: Profile (76).pdf\n",
      "Extracting text from resume: Profile (77).pdf\n",
      "Extracting text from resume: Profile (78).pdf\n",
      "Extracting text from resume: Profile (79).pdf\n",
      "Extracting text from resume: Profile (8).pdf\n",
      "Extracting text from resume: Profile (80).pdf\n",
      "Extracting text from resume: Profile (81).pdf\n",
      "Extracting text from resume: Profile (82).pdf\n",
      "Extracting text from resume: Profile (83).pdf\n",
      "Extracting text from resume: Profile (84).pdf\n",
      "Extracting text from resume: Profile (85).pdf\n",
      "Extracting text from resume: Profile (86).pdf\n",
      "Extracting text from resume: Profile (87).pdf\n",
      "Extracting text from resume: Profile (88).pdf\n",
      "Extracting text from resume: Profile (89).pdf\n",
      "Extracting text from resume: Profile (9).pdf\n",
      "Extracting text from resume: Profile (90).pdf\n",
      "Extracting text from resume: Profile (91).pdf\n",
      "Extracting text from resume: Profile (92).pdf\n",
      "Extracting text from resume: Profile (93).pdf\n",
      "Extracting text from resume: Profile (94).pdf\n",
      "Extracting text from resume: Profile (95).pdf\n",
      "Extracting text from resume: Profile (96).pdf\n",
      "Extracting text from resume: Profile (97).pdf\n",
      "Extracting text from resume: Profile (98).pdf\n",
      "Extracting text from resume: Profile (99).pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162228.770.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162244.931.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162508.746.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162543.724.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162559.521.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162622.964.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162629.532.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162634.403.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162640.089.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162646.021.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162709.413.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162713.961.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162721.627.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162751.114.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162756.183.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162800.950.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162902.090.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162927.914.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T162957.471.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T163056.440.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T163103.533.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T163123.959.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T163657.540.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164358.323.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164407.651.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164423.196.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164448.759.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164508.875.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164613.129.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164622.329.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164642.548.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164653.430.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164722.911.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T164831.966.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T165006.661.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T165048.971.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T165103.441.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T165207.738.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T165233.212.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T165330.459.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T165456.196.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T171606.222.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T171609.901.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T171613.889.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T171630.757.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T171642.303.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T171746.264.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T171822.661.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T172315.599.pdf\n",
      "Extracting text from resume: Profile - 2024-12-18T172352.456.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T165742.181.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T165751.329.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T165800.721.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T165807.751.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T165815.425.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T165957.407.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170006.715.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170140.720.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170313.423.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170346.290.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170406.860.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170415.828.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170423.267.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170431.756.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170440.156.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170447.541.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170455.991.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170600.102.pdf\n",
      "Extracting text from resume: Profile - 2025-02-10T170607.705.pdf\n",
      "Extracting text from resume: Profile.pdf\n",
      "Extracting text from resume: Quality Control Analyst.pdf\n",
      "Extracting text from resume: received_1004742418381899.jpeg\n",
      "Extracting text from resume: received_1121030216485818.jpeg\n",
      "Extracting text from resume: received_1134760891280906.jpeg\n",
      "Extracting text from resume: received_1140454304033420.jpeg\n",
      "Extracting text from resume: received_1150455673473892.jpeg\n",
      "Extracting text from resume: received_1154799006314782.jpeg\n",
      "Extracting text from resume: received_1171730537914739.jpeg\n",
      "Extracting text from resume: received_1173375001070265.jpeg\n",
      "Extracting text from resume: received_1180218723521863.jpeg\n",
      "Extracting text from resume: received_1182560790539567.jpeg\n",
      "Extracting text from resume: received_1190100832506405.jpeg\n",
      "Extracting text from resume: received_1198066701698959.jpeg\n",
      "Extracting text from resume: received_1250477259291368.jpeg\n",
      "Extracting text from resume: received_1256135508808576.jpeg\n",
      "Extracting text from resume: received_1289009059062311.jpeg\n",
      "Extracting text from resume: received_1308623233690598.jpeg\n",
      "Extracting text from resume: received_1322783488869977.jpeg\n",
      "Extracting text from resume: received_1328394348594653.jpeg\n",
      "Extracting text from resume: received_1344656170123341.jpeg\n",
      "Extracting text from resume: received_1354728528855886.jpeg\n",
      "Extracting text from resume: received_1377373396606571.jpeg\n",
      "Extracting text from resume: received_1399505344647858.jpeg\n",
      "Extracting text from resume: received_1417128056363278.jpeg\n",
      "Extracting text from resume: received_1516740205878954.png\n",
      "Extracting text from resume: received_1542764346388075.jpeg\n",
      "Extracting text from resume: received_1546127119395574.jpeg\n",
      "Extracting text from resume: received_1555183751832790.jpeg\n",
      "Extracting text from resume: received_1557951674895824.jpeg\n",
      "Extracting text from resume: received_1569473643944654.jpeg\n",
      "Extracting text from resume: received_1579239086068669.jpeg\n",
      "Extracting text from resume: received_1597306634264532.jpeg\n",
      "Extracting text from resume: received_1611623490232038.jpeg\n",
      "Extracting text from resume: received_1708791259980283.jpeg\n",
      "Extracting text from resume: received_1738019047112704.jpeg\n",
      "Extracting text from resume: received_1785651845618779.jpeg\n",
      "Extracting text from resume: received_1807965416658179.jpeg\n",
      "Extracting text from resume: received_1874043136735640.jpeg\n",
      "Extracting text from resume: received_2138958399901756.jpeg\n",
      "Extracting text from resume: received_2638278739716158.jpeg\n",
      "Extracting text from resume: received_28638656979112893.jpeg\n",
      "Extracting text from resume: received_2975395262627713.jpeg\n",
      "Extracting text from resume: received_3498528750442880.jpeg\n",
      "Extracting text from resume: received_3798968280320652.jpeg\n",
      "Extracting text from resume: received_3904803623103315.jpeg\n",
      "Extracting text from resume: received_3908001002805228.jpeg\n",
      "Extracting text from resume: received_3917624835187737.jpeg\n",
      "Extracting text from resume: received_4071809819723504.jpeg\n",
      "Extracting text from resume: received_500485656435379.jpeg\n",
      "Extracting text from resume: received_504265682421332.jpeg\n",
      "Extracting text from resume: received_512409761533570.jpeg\n",
      "Extracting text from resume: received_550740277321438.jpeg\n",
      "Extracting text from resume: received_551307377264423.jpeg\n",
      "Extracting text from resume: received_594281646774756.jpeg\n",
      "Extracting text from resume: received_599077029613923.jpeg\n",
      "Extracting text from resume: received_608571478748676.jpeg\n",
      "Extracting text from resume: received_609198211908063.jpeg\n",
      "Extracting text from resume: received_609258848587407.jpeg\n",
      "Extracting text from resume: received_615931194652631.jpeg\n",
      "Extracting text from resume: received_616094604467134.jpeg\n",
      "Extracting text from resume: received_616817431205206.jpeg\n",
      "Extracting text from resume: received_625841780403117.jpeg\n",
      "Extracting text from resume: received_625887600144101.jpeg\n",
      "Extracting text from resume: received_633314069347869.jpeg\n",
      "Extracting text from resume: received_636970962514932.jpeg\n",
      "Extracting text from resume: received_638510128677162.jpeg\n",
      "Extracting text from resume: received_639000388711733.jpeg\n",
      "Extracting text from resume: received_641096628500608.jpeg\n",
      "Extracting text from resume: received_651848744041830.jpeg\n",
      "Extracting text from resume: received_652433687320208.jpeg\n",
      "Extracting text from resume: received_687109190305658.jpeg\n",
      "Extracting text from resume: received_693363296460084.jpeg\n",
      "Extracting text from resume: received_7732554440182858.jpeg\n",
      "Extracting text from resume: received_823346056639891.jpeg\n",
      "Extracting text from resume: received_868193805360970.jpeg\n",
      "Extracting text from resume: received_889398693164671.jpeg\n",
      "Extracting text from resume: received_9047403322036305.jpeg\n",
      "Extracting text from resume: received_9129354523826891.jpeg\n",
      "Extracting text from resume: received_9212982515423113.jpeg\n",
      "Extracting text from resume: received_930734075894136.jpeg\n",
      "Extracting text from resume: received_9409310825818450.jpeg\n",
      "Extracting text from resume: received_9505808446106440.jpeg\n",
      "Extracting text from resume: received_959181103077595.jpeg\n",
      "Extracting text from resume: received_9637231222977182.jpeg\n",
      "Extracting text from resume: received_975496387864320.jpeg\n",
      "Extracting text from resume: received_979456184145604.jpeg\n",
      "Extracting text from resume: received_980518866937402.jpeg\n",
      "Extracting text from resume: received_985633039675589.jpeg\n",
      "Extracting text from resume: Recruiter.pdf\n",
      "Extracting text from resume: Student-0.pdf\n",
      "Extracting text from resume: Student-1.pdf\n",
      "Extracting text from resume: Student-2.pdf\n",
      "Extracting text from resume: Training-Manager.pdf\n",
      "Extracting text from resume: Va.pdf\n",
      "Extracting text from resume: Video Editor.pdf\n",
      "Extracting text from job requirement: Admin Assistant.docx\n",
      "Extracting text from job requirement: Administrative Associate.docx\n",
      "Extracting text from job requirement: Amazon Listing Specialist.docx\n",
      "Extracting text from job requirement: AU Legal Admin Assistant.docx\n",
      "Extracting text from job requirement: Automation Test Engineer.docx\n",
      "Extracting text from job requirement: Bilingual Speaker.docx\n",
      "Extracting text from job requirement: Bookkeeper.docx\n",
      "Extracting text from job requirement: Business Development Analyst.docx\n",
      "Extracting text from job requirement: Call center agent.docx\n",
      "Extracting text from job requirement: CHAT SUPPORT AGENT.docx\n",
      "Extracting text from job requirement: Client Partner Philippines.docx\n",
      "Extracting text from job requirement: Cloud Support Engineer.docx\n",
      "Extracting text from job requirement: Contract Administrator.docx\n",
      "Extracting text from job requirement: Contract Management Specialist.docx\n",
      "Extracting text from job requirement: Customer Support Representative.docx\n",
      "Extracting text from job requirement: Data Collection Coordinator.docx\n",
      "Extracting text from job requirement: Digital Account Coordinator.docx\n",
      "Extracting text from job requirement: Digital Client Success Manager.docx\n",
      "Extracting text from job requirement: Digital Marketing Assistant.docx\n",
      "Extracting text from job requirement: Digital Marketing Salesperson.docx\n",
      "Extracting text from job requirement: Document Scanner.docx\n",
      "Extracting text from job requirement: Executive Assistan1.docx\n",
      "Extracting text from job requirement: Executive Assistant.docx\n",
      "Extracting text from job requirement: Freelance Non.docx\n",
      "Extracting text from job requirement: Freelance Text.docx\n",
      "Extracting text from job requirement: Full Stack Developer.docx\n",
      "Extracting text from job requirement: Full Stack Engineer.docx\n",
      "Extracting text from job requirement: Help Desk Representative.docx\n",
      "Extracting text from job requirement: HR Admin.docx\n",
      "Extracting text from job requirement: Internal Communication Specialist.docx\n",
      "Extracting text from job requirement: Junior Developer.docx\n",
      "Extracting text from job requirement: Junior Recruiter for Freelance Projects.docx\n",
      "Extracting text from job requirement: Klaviyo Email Marketing Specialist.docx\n",
      "Extracting text from job requirement: Listing Content Intern.docx\n",
      "Extracting text from job requirement: Marketing Virtual Assistant.docx\n",
      "Extracting text from job requirement: Paid Media Specialist.docx\n",
      "Extracting text from job requirement: Part.docx\n",
      "Extracting text from job requirement: Personal Assistant.docx\n",
      "Extracting text from job requirement: Quality Assurance Automation Engineer.docx\n",
      "Extracting text from job requirement: Sales and Marketing Admin Associate.docx\n",
      "Extracting text from job requirement: Sales and Virtual Assistant.docx\n",
      "Extracting text from job requirement: Sales Training Assistant.docx\n",
      "Extracting text from job requirement: Senior Full Stack.docx\n",
      "Extracting text from job requirement: Senior Fullstack Software Engineer.docx\n",
      "Extracting text from job requirement: SEO Copywriter.docx\n",
      "Extracting text from job requirement: Team Administrative Assistant.docx\n",
      "Extracting text from job requirement: Test Automation Engineer.docx\n",
      "Extracting text from job requirement: Trainee.docx\n",
      "Extracting text from job requirement: US Paralegal Admin.docx\n",
      "Extracting text from job requirement: Verification Specialist.docx\n",
      "Extracting text from job requirement: Voice Over Artist.docx\n",
      "Extraction complete. Data saved to output/scored-dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import textract\n",
    "import PyPDF2\n",
    "import docx\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import inflect\n",
    "\n",
    "# Download necessary nltk data (if needed)\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Set up inflect engine for number-to-word conversion\n",
    "p = inflect.engine()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Set Tesseract OCR Path (Windows Only)\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "#----------------------------\n",
    "# TEXT EXTRACTION FUNCTIONS\n",
    "#----------------------------\n",
    "def extract_text_from_docx(file_path):\n",
    "    try:\n",
    "        doc = docx.Document(file_path)\n",
    "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {file_path} using python-docx: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
    "            return text if text else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {file_path} using PyPDF2: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_from_image(file_path):\n",
    "    try:\n",
    "        image = Image.open(file_path)\n",
    "        text = pytesseract.image_to_string(image, config='--psm 6')\n",
    "        return text.strip() if text else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {file_path} using OCR: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text(file_path):\n",
    "    \"\"\"Detect file type and extract text accordingly.\"\"\"\n",
    "    text = None\n",
    "    if file_path.endswith(\".docx\"):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif file_path.endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        text = extract_text_from_image(file_path)\n",
    "    \n",
    "    # Fallback to Textract if primary extraction fails\n",
    "    if text is None:\n",
    "        try:\n",
    "            text = textract.process(file_path).decode(\"utf-8\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {file_path} using textract: {e}\")\n",
    "            return None\n",
    "    \n",
    "    return text\n",
    "\n",
    "#----------------------------\n",
    "# TEXT PREPROCESSING\n",
    "#----------------------------\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Lowercase, remove special characters, normalize numbers, lemmatize, and remove stopwords.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Normalize numbers (convert digits to words)\n",
    "    words = text.split()\n",
    "    normalized_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():  # Check if it's a number\n",
    "            try:\n",
    "                word = p.number_to_words(int(word))  # Convert to words\n",
    "            except:\n",
    "                word = p.number_to_words(int(word))\n",
    "                # pass  # If conversion fails, keep the original number\n",
    "        normalized_words.append(word)\n",
    "    \n",
    "    text = \" \".join(normalized_words)\n",
    "\n",
    "    # Remove special characters\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    \n",
    "    # Lemmatization and Stopword Removal\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "\n",
    "    return text\n",
    "\n",
    "#----------------------------\n",
    "# JACCARD SIMILARITY\n",
    "#----------------------------\n",
    "def calculate_jaccard_similarity(text1, text2):\n",
    "    set1, set2 = set(text1.split()), set(text2.split())\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union) if union else 0, intersection\n",
    "\n",
    "#----------------------------\n",
    "# PROCESS FILES & GENERATE CSV\n",
    "#----------------------------\n",
    "def process_files(resume_folder, job_folder, output_csv):\n",
    "    data = []\n",
    "    resumes = []\n",
    "    job_requirements = []\n",
    "    \n",
    "    # Extract and preprocess resumes\n",
    "    for filename in os.listdir(resume_folder):\n",
    "        file_path = os.path.join(resume_folder, filename)\n",
    "        if file_path.endswith((\".pdf\", \".docx\", \".jpg\", \".jpeg\", \".png\")):\n",
    "            print(f\"Extracting text from resume: {filename}\")\n",
    "            text = extract_text(file_path)\n",
    "            if text:\n",
    "                resumes.append({\"filename\": filename, \"text\": preprocess_text(text)})\n",
    "\n",
    "    # Extract and preprocess job descriptions\n",
    "    for filename in os.listdir(job_folder):\n",
    "        file_path = os.path.join(job_folder, filename)\n",
    "        if file_path.endswith((\".pdf\", \".docx\", \".jpg\", \".jpeg\", \".png\")):\n",
    "            print(f\"Extracting text from job requirement: {filename}\")\n",
    "            text = extract_text(file_path)\n",
    "            if text:\n",
    "                job_requirements.append({\"filename\": filename, \"text\": preprocess_text(text)})\n",
    "\n",
    "    # Compute Jaccard similarity\n",
    "    for resume in resumes:\n",
    "        for job in job_requirements:\n",
    "            jaccard_score_value, common_words = calculate_jaccard_similarity(resume[\"text\"], job[\"text\"])\n",
    "            data.append({\n",
    "                \"Resume Text\": resume[\"text\"],\n",
    "                \"Job Text\": job[\"text\"],\n",
    "                \"Jaccard Score\": jaccard_score_value,\n",
    "                \"Common Words\": \" \".join(common_words)  # Convert set to string\n",
    "            })\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Extraction complete. Data saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "resume_folder = \"data-for-training/resumes\"  # Change this to your resume folder path\n",
    "job_folder = \"data-for-training/job requirements\"  # Change this to your job requirements folder path\n",
    "output_csv = \"output/scored-dataset.csv\"\n",
    "process_files(resume_folder, job_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTO-LABELLING BASED ON JACCARD SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      " Label\n",
      "0    11780\n",
      "1     2908\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the extracted text dataset\n",
    "df = pd.read_csv(\"output/scored-dataset.csv\")\n",
    "\n",
    "# Ensure \"Jaccard Score\" exists\n",
    "if \"Jaccard Score\" not in df.columns:\n",
    "    raise ValueError(\"Jaccard Score column is missing from the dataset!\")\n",
    "\n",
    "# # Convert Jaccard Score to float, handling errors\n",
    "# df[\"Jaccard Score\"] = pd.to_numeric(df[\"Jaccard Score\"], errors=\"coerce\")\n",
    "\n",
    "# # Handle NaN values (replace with 0 to avoid errors)\n",
    "# df[\"Jaccard Score\"] = df[\"Jaccard Score\"].fillna(0)\n",
    "\n",
    "# Apply label based on Jaccard Score threshold\n",
    "df[\"Label\"] = df[\"Jaccard Score\"].apply(lambda x: 1 if x > 0.05 else 0)\n",
    "\n",
    "# Save the labeled dataset for XGBoost classification\n",
    "df.to_csv(\"output/labeled-data.csv\", index=False)\n",
    "\n",
    "# Display label distribution\n",
    "print(\"Label distribution:\\n\", df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:43:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6099387338325392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.52      0.69      2387\n",
      "           1       0.32      0.98      0.49       551\n",
      "\n",
      "    accuracy                           0.61      2938\n",
      "   macro avg       0.66      0.75      0.59      2938\n",
      "weighted avg       0.87      0.61      0.65      2938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the labeled dataset\n",
    "df = pd.read_csv(\"output/labeled-data.csv\")\n",
    "\n",
    "# Feature extraction: Use TF-IDF to convert text into numerical format\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "X = vectorizer.fit_transform(df[\"Resume Text\"] + \" \" + df[\"Job Text\"])  # Combine both texts\n",
    "y = df[\"Label\"]  # Target variable (0 = Not Suitable, 1 = Suitable)\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Train XGBoost model\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",  # Binary classification\n",
    "    \"eval_metric\": \"logloss\",\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 100,\n",
    "}\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred = [1 if p >= 0.05 else 0 for p in y_pred]\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model\n",
    "model.save_model(\"xgboost_resume_classifier.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“Œ Steps to Predict New Resumes\n",
    "\n",
    "âœ… 1. Load Trained XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Load the trained model correctly\n",
    "xgb_model = xgb.Booster()\n",
    "xgb_model.load_model(\"xgboost_resume_classifier.json\")  # Load the JSON model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Step 2: Load & Preprocess New Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load new resumes dataset (Assuming it's a CSV)\n",
    "new_resumes = pd.read_csv(\"output/new_resumes.csv\")  # Update with your filename\n",
    "\n",
    "# Apply the same text preprocessing function\n",
    "new_resumes[\"processed_text\"] = new_resumes[\"Resume Text\"].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… 3. Compute Jaccard Score Against Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement job recommendations for rejected resumes, you can follow these steps:\n",
    "\n",
    "Identify Rejected Resumes: Filter resumes where the model predicts them as \"Not Suitable\" (label = 0).\n",
    "Compare with Other Job Descriptions: Compute similarity scores (e.g., Jaccard, cosine similarity) between rejected resumes and other job descriptions.\n",
    "Rank Suitable Jobs: Sort job descriptions based on similarity scores and suggest the top matches.\n",
    "Save Recommendations: Store job suggestions in a CSV or database for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load datasets\n",
    "resumes_df = pd.read_csv(\"resumes.csv\")  # Your dataset containing resumes and suitability labels\n",
    "jobs_df = pd.read_csv(\"job_descriptions.csv\")  # Your dataset containing job descriptions\n",
    "\n",
    "# Filter out rejected resumes\n",
    "rejected_resumes = resumes_df[resumes_df[\"Label\"] == 0]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "resume_vectors = vectorizer.fit_transform(rejected_resumes[\"Resume Text\"])\n",
    "job_vectors = vectorizer.transform(jobs_df[\"Job Requirement Text\"])\n",
    "\n",
    "# Compute Cosine Similarity\n",
    "similarity_matrix = cosine_similarity(resume_vectors, job_vectors)\n",
    "\n",
    "# Generate job recommendations\n",
    "job_suggestions = []\n",
    "for i, resume in rejected_resumes.iterrows():\n",
    "    top_indices = similarity_matrix[i].argsort()[::-1][:3]  # Get top 3 job matches\n",
    "    suggested_jobs = jobs_df.iloc[top_indices][\"Job Requirement Text\"].tolist()\n",
    "    \n",
    "    job_suggestions.append({\n",
    "        \"Resume\": resume[\"Resume Text\"],\n",
    "        \"Suggested Jobs\": suggested_jobs\n",
    "    })\n",
    "\n",
    "# Save recommendations\n",
    "recommendations_df = pd.DataFrame(job_suggestions)\n",
    "recommendations_df.to_csv(\"job_recommendations.csv\", index=False)\n",
    "\n",
    "print(\"Job recommendations saved to job_recommendations.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
